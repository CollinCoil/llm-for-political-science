{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer\n",
    "from semantic_similarity import calculate_semantic_similarity\n",
    "from sentence_tokenizer import process_directory\n",
    "from summarization import summarize_document_with_pipeline\n",
    "from information_clustering import create_document_embeddings, perform_clustering_and_visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Textual Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process both directories\n",
    "amici_dir = '../Data/Amici'\n",
    "opinions_dir = '../Data/Opinions'\n",
    "metadata_file = '../Data/metadata.csv'\n",
    "amici_jsonl = '../Data/amici_sentences.jsonl'\n",
    "opinions_jsonl = '../Data/opinions_sentences.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amici_metadata = process_directory(amici_dir, amici_jsonl)\n",
    "opinions_metadata = process_directory(opinions_dir, opinions_jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and save the semantic similarity matrix\n",
    "results = calculate_semantic_similarity(opinions_jsonl, amici_jsonl, metadata_file, output_dir=\"../Data/similarity_matrices\", threshold=0.9, model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_of_interest = \"Burwell v. Hobby Lobby\"\n",
    "\n",
    "if case_of_interest in results:\n",
    "    print(f\"Highly similar pairs for case '{case_of_interest}':\")\n",
    "    for pair in results[case_of_interest][\"highly_similar_pairs\"]:\n",
    "        print(\"Opinion Sentence:\", pair[\"opinion_sentence\"])\n",
    "        print(\"Amicus Sentence:\", pair[\"amicus_sentence\"])\n",
    "        print(\"Similarity Score:\", pair[\"similarity_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = list(results.keys())\n",
    "percent_copied_values = [results[case][\"percent_copied\"] for case in cases]\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(cases, percent_copied_values, color='mediumseagreen')\n",
    "plt.axhline(y=2.7, color='black', linestyle='--', label='2.7% (Collins et al., 2015)')\n",
    "plt.xlabel('Case')\n",
    "plt.ylabel('Percent Copied')\n",
    "plt.title('Percent of Opinion Text Similar to Amici Briefs by Case')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables for calculating averages\n",
    "total_percent_copied = 0\n",
    "total_weighted_percent_copied = 0\n",
    "total_words_in_all_opinions = 0\n",
    "\n",
    "# Loop through each case in results\n",
    "for case, case_data in results.items():\n",
    "    percent_copied = case_data[\"percent_copied\"]\n",
    "    opinion_length_words = case_data[\"total_words\"]  # Ensure this is in the results data\n",
    "\n",
    "    # Add to the simple total\n",
    "    total_percent_copied += percent_copied\n",
    "    \n",
    "    # Add to the weighted total\n",
    "    total_weighted_percent_copied += percent_copied * opinion_length_words\n",
    "    total_words_in_all_opinions += opinion_length_words\n",
    "\n",
    "# Calculate averages\n",
    "num_cases = len(results)\n",
    "simple_average = total_percent_copied / num_cases if num_cases > 0 else 0\n",
    "weighted_average = (total_weighted_percent_copied / total_words_in_all_opinions) if total_words_in_all_opinions > 0 else 0\n",
    "\n",
    "# Print the results\n",
    "print(f\"Simple Average Percentage of Text Copied: {simple_average:.2f}%\")\n",
    "print(f\"Opinion-Length Weighted Average Percentage of Text Copied: {weighted_average:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer\n",
    "model_name = 'google/bigbird-roberta-large'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def count_tokens(directory):\n",
    "    token_counts = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                text = file.read()\n",
    "\n",
    "            # Tokenize the text to count tokens\n",
    "            tokens = tokenizer(text, truncation=False)\n",
    "            num_tokens = len(tokens['input_ids'])\n",
    "            token_counts.append(num_tokens)\n",
    "\n",
    "    return token_counts\n",
    "\n",
    "# Count tokens in each document\n",
    "directory = \"Data/Amici\"\n",
    "token_counts = count_tokens(directory)\n",
    "\n",
    "# Plot histogram of token counts\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(token_counts, bins=30, color='mediumseagreen', edgecolor='black')\n",
    "plt.axvline(x=4096, color='black', linestyle='--', label='4096 Token Limit')\n",
    "plt.xlabel(\"Number of Tokens\")\n",
    "plt.ylabel(\"Number of Documents\")\n",
    "plt.title(\"Histogram of Amicus Curiae Token Counts\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define paths and call the embedding creation function\n",
    "DATA_DIRS = [\"../Data/Amici\"]\n",
    "METADATA_FILE = \"../Data/metadata.csv\"\n",
    "OUTPUT_EMBEDDINGS = \"../Data/embeddings.pt\"\n",
    "OUTPUT_LABELS = \"../Data/labels.csv\"\n",
    "\n",
    "\n",
    "# create_document_embeddings(DATA_DIRS, METADATA_FILE, OUTPUT_EMBEDDINGS, OUTPUT_LABELS)\n",
    "\n",
    "# Define paths and call the clustering and visualization function\n",
    "N_CLUSTERS = 6\n",
    "OUTPUT_PLOT = \"../Data/clustering_visualization.png\"\n",
    "perform_clustering_and_visualize(OUTPUT_EMBEDDINGS, OUTPUT_LABELS, N_CLUSTERS, OUTPUT_PLOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "file_path = \"../Data/nfib v sebelius syllabus.txt\"\n",
    "model_names = [\n",
    "    \"google/flan-t5-small\",\n",
    "    \"google/flan-t5-base\",\n",
    "    \"google/flan-t5-large\",\n",
    "    \"google/flan-t5-xl\"]\n",
    "\n",
    "summaries = summarize_document_with_pipeline(file_path, model_names, max_input_length=512)\n",
    "\n",
    "\n",
    "model_names = [\n",
    "    \"allenai/led-base-16384\",\n",
    "    \"allenai/led-base-16384-ms2\",\n",
    "    \"allenai/led-base-16384-cochrane\",\n",
    "    \"allenai/led-large-16384\", \n",
    "    \"allenai/led-large-16384-arxiv\", \n",
    "]\n",
    "summaries = summarize_document_with_pipeline(file_path, model_names, max_input_length=2900)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
